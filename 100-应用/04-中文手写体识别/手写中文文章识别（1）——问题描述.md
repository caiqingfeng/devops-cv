https://blog.csdn.net/foreseerwang/article/details/80833749

针对这样一篇手写文章的识别，首先需要进行图片预处理：包括纠正畸变、降噪、文字图片切割等等。输出可能包括两种情况：第一种是切出每个字，第二种是切出每句话或每行文字。考虑到通用性，这里使用第一种情况，即最终输出单个字的图片数据。假设单个字的图片为灰度64*64，则输出数据应该为：N*64*64*1。其中N为字数（包括标点符号），不是batch_size。通用图片的预处理其实是一个相当有难度的课题，个人能力和精力有限，在本项目中并未涉及，而是直接使用单字图片。



现在问题转变成手写中文图片序列的识别问题，其中涉及如下两个关键技术点（后文将专门详细介绍）：

1. 训练集的构建。作为个人学习者来说，不太可能获得大量真实手写文章训练集。因此，只能考虑自行构建，这就需要两部分资源，一是手写中文文字图库，二是中文文章。考虑到版权问题，这两部分资源我都不能传到网上。

    a) 手写中文文字图库，推荐中科院自动化所的hwdb，这个链接（http://www.nlpr.ia.ac.cn/databases/handwriting/Home.html）中可以免费下载到3755个中文字符的手写中文图库，这个数字偏少，但作为个人练习倒也差不多了。如果需要更大的图库，可以按照这个链接中的要求填表索取；

    b) 中文文章，可以从一些作文网站或新闻网站自行爬取；

    c) 训练集构建，从中文文章中读取文字，在手写中文图库中找到相应的手写图片作为模型输入。以每句话作为一个训练样本，假设一句话有N个字，则一个训练样本的shape为：N*64*64*1；而一个训练样本batch的shape为：[batch_size, Nmax, 64, 64, 1]。注意，每句话的长度可能不一样，因此，需要同时提供sequence_length数据，其shape为[batch_size]，其中每个元素为对应训练样本(每句话)的长度。Nmax为一句话（一个训练样本）可能的最大字数（或者是设定的一个数，对于超出这个数的句子进行逐段截取，形成多个训练样本）。最终的训练样本batch包括三部分：images_batch (shape为[batch_size, Nmax, 64, 64, 1])、labels_batch（shape为[batch_size, Nmax]）、sequence_length_batch (shape为[batch_size])三部分内容。



2. 模型构建。单纯的手写文字识别，相对来说，很容易实现。网上已经有针对hwdb这个中文手写数据库的程序范例，例如：https://zhuanlan.zhihu.com/p/24698483，及其改进版本：https://github.com/soloice/Chinese-Character-Recognition。但是，这些都是针对单个手写文字图片识别的，只需要卷积神经网络（CNN）模型即可；而针对一篇手写文章，或者说手写文字图片序列，需要考虑前后文信息提高识别率，因此至少需要使用CNN+LSTM/RNN模型；实际上，为了充分学习序列的前后文关系，通常还需要在LSTM后面加上Beam Search或Viterbi解码。最终，我的模型结构为：CNN + 双向LSTM + Viterbi解码（CRF）。其中CNN部分采用了上述改进版本的结构。

    a) Beam Search和Viterbi解码的区别，简单的说，BeamSearch是空间剪枝，而Viterbi算法是时间剪枝。详见这个链接里的讨论：https://www.zhihu.com/question/20136144
