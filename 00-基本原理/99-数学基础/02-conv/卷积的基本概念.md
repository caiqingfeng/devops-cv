https://blog.csdn.net/a1154761720/article/details/53411365?utm_source=blogxgwz6

1. 卷积核：可以看作对某个局部的加权求和；它是对应局部感知，它的原理是在观察某个物体时我们既不能观察每个像素也不能一次观察整体，而是先从局部开始认识，这就对应了卷积。卷积核的大小一般有1x1,3x3和5x5的尺寸。卷积核的个数就对应输出的通道数，这里需要说明的是对于输入的每个通道，输出每个通道上的卷积核是不一样的。比如输入是28x28x192(WxDxK,K代表通道数)，然后在3x3的卷积核，卷积通道数为128，那么卷积的参数有3x3x192x128,其中前两个对应的每个卷积里面的参数，后两个对应的卷积总的个数。 
2. 池化（pooling）：卷积特征往往对应某个局部的特征。要得到globa的特征需要将全局的特征就行一个aggregation。池化就是这样一个操作，对于每个卷积通道，将更大尺寸（甚至是globa）上的卷积特征进行pooling就可以得到更有全局性的特征。这里的pooling当然就对应了cross region。与1x1的卷积相对应，后者可以看作一个cross channel的pooling操作。pooling的另外一个作用就是升维或者降维，后面我们可以看到1x1的卷积也有相似的作用。

Network in Network（NIN）
要介绍Inception网络结构首先应该介绍一下NIN(Network in Network)网络模型，2014年新加坡国立大学发表了一篇关于计算机视觉图像分类的论文，提到采用了一种新的网络结构NIN实现图像分类，该论文的第二作者颜水成毕业于北京大学数学系，现任360人工智能研究院院长与首席科学家。NIN主要思想是认为CNN网络中卷积滤波是基于线性滤波器实现的，抽象能力不够，所以一般是用一大堆filter把所有特征都找出来，但是这样就导致网络参数过大，论文作者提出通过MLP（多个权重阶层组成+一个非线性激活函数）对输入区域通过MLP产生一个输出feature map，然后继续滑动MLP窗口