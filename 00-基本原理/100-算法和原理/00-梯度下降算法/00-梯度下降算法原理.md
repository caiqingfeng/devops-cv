 梯度:  是表示模型或者函数在某个点的位置法向量,所以它的方向表示下降最快或者上升最快也就很好理解了

 梯度下降法求的是极小值，而不是最小值
梯度下降法常常用来求凸函数的最小值，例如机器学习中各种代价函数的最小值
步长的选取很关键，步长过长达不到极值点甚至会发散，步长太短导致收敛时间过长
斯坦福的机器学习视频中建议按照[0.001,0.003,0.01,0.03,…]的顺序尝试设置步长，同时观察函数值选择收敛最快的步长
步长也可以设置为非固定值，根据迭代的情况变化
下降的初始点一般设置为从原点开始